<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Audio Silence Dials</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/react/18.2.0/umd/react.production.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/react-dom/18.2.0/umd/react-dom.production.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/babel-standalone/7.23.5/babel.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gauge.js/1.3.7/gauge.min.js"></script>
    <style>
      body {
        display: flex;
        justify-content: center;
        align-items: center;
        min-height: 100vh;
        margin: 0;
        background-color: #f3f4f6;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
          sans-serif;
      }
      .container {
        padding: 2rem;
        background: white;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        margin: 1rem;
        text-align: center;
      }
      .dials-container {
        display: flex;
        flex-direction: column;
        flex-wrap: wrap;
        gap: 2rem;
        justify-content: center;
        padding: 2rem;
      }
      .message {
        min-height: 3em;
        margin-top: 1rem;
      }
    </style>
  </head>
  <body>
    <div id="root"></div>

    <script type="text/babel">
      const AudioSilenceDial = ({ sensitivity, messages, label }) => {
        const [silenceTime, setSilenceTime] = React.useState(0);
        const [isListening, setIsListening] = React.useState(false);
        const [error, setError] = React.useState("");
        const gaugeRef = React.useRef(null);
        const canvasRef = React.useRef(null);
        const audioContextRef = React.useRef(null);
        const analyserRef = React.useRef(null);
        const animationFrameRef = React.useRef(null);
        const lastSoundTimeRef = React.useRef(Date.now());

        React.useEffect(() => {
          // Initialize Gauge
          const gauge = new Gauge(canvasRef.current).setOptions({
            angle: -0.25,
            lineWidth: 0.2,
            radiusScale: 0.9,
            pointer: {
              length: 0.6,
              strokeWidth: 0.035,
              color: "#000000",
            },
            limitMax: false,
            limitMin: false,
            colorStart: "#4CAF50", // Green
            colorStop: "#FF5252", // Red
            strokeColor: "#E0E0E0",
            generateGradient: true,
            highDpiSupport: true,
            staticLabels: {
              font: "12px sans-serif",
              labels: [0, 2, 4, 6, 8, 10],
              color: "#000000",
              fractionDigits: 0,
            },
            staticZones: [
              { strokeStyle: "#4CAF50", min: 0, max: 2 }, // Green
              { strokeStyle: "#8BC34A", min: 2, max: 4 }, // Light Green
              { strokeStyle: "#FFC107", min: 4, max: 6 }, // Yellow
              { strokeStyle: "#FF9800", min: 6, max: 8 }, // Orange
              { strokeStyle: "#FF5252", min: 8, max: 10 }, // Red
            ],
          });

          gauge.maxValue = 10;
          gauge.setMinValue(0);
          gauge.animationSpeed = 32;
          gauge.set(0);

          gaugeRef.current = gauge;

          // Setup Audio
          const setupAudio = async () => {
            try {
              const stream = await navigator.mediaDevices.getUserMedia({
                audio: true,
              });
              audioContextRef.current = new (window.AudioContext ||
                window.webkitAudioContext)();
              const source =
                audioContextRef.current.createMediaStreamSource(stream);
              analyserRef.current = audioContextRef.current.createAnalyser();
              analyserRef.current.fftSize = 2048;
              source.connect(analyserRef.current);
              setIsListening(true);
              startMonitoring();
            } catch (err) {
              setError("Microphone access denied or not available");
            }
          };

          setupAudio();

          return () => {
            if (animationFrameRef.current) {
              cancelAnimationFrame(animationFrameRef.current);
            }
            if (audioContextRef.current) {
              audioContextRef.current.close();
            }
          };
        }, []);

        const startMonitoring = () => {
          const dataArray = new Uint8Array(
            analyserRef.current.frequencyBinCount,
          );

          const checkAudio = () => {
            analyserRef.current.getByteFrequencyData(dataArray);
            const average =
              dataArray.reduce((a, b) => a + b) / dataArray.length;

            const now = Date.now();
            if (average > sensitivity) {
              lastSoundTimeRef.current = now;
              setSilenceTime(0);
              gaugeRef.current.set(0);
            } else {
              const silenceDuration = (now - lastSoundTimeRef.current) / 1000;
              const newSilenceTime = Math.min(silenceDuration, 10);
              setSilenceTime(newSilenceTime);
              gaugeRef.current.set(newSilenceTime);
            }

            animationFrameRef.current = requestAnimationFrame(checkAudio);
          };

          checkAudio();
        };

        const getCurrentMessage = () => {
          const secondsPassed = Math.floor(silenceTime);
          return messages[secondsPassed] || messages[messages.length - 1];
        };

        return (
          <div className="container">
            <h3>Sensitivity: {sensitivity}</h3>
            <canvas ref={canvasRef} width="200" height="200"></canvas>
            <div className="message">
              {isListening ? getCurrentMessage() : error || "Starting..."}
            </div>
          </div>
        );
      };

      const App = () => {
        const messages = [
          "Listening...",
          "Ok... I'm listening",
          "Getting silence...",
          "Quite quiet...",
          "Very quiet now...",
          "Is anyone there?",
          "Hello...?",
          "This is awkward...",
          "Should I say something?",
          "Really awkward now...",
          "Maximum awkwardness!",
        ];

        return (
          <div className="dials-container">
            <h1>Awkwardrometer</h1>
            <AudioSilenceDial
              sensitivity={35}
              messages={messages}
              label="High Sensitivity"
            />
          </div>
        );
      };

      ReactDOM.render(<App />, document.getElementById("root"));
    </script>
  </body>
</html>
